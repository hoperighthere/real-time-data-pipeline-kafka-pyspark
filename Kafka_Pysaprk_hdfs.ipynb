{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59c8f5-f13f-426e-abd3-a6d78fe20275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.streaming import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bf21a-03ce-4925-af47-24e79cc3745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_jars =  (\"{},{},{},{},{},{}\".format(os.getcwd() + \"/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar\",  \n",
    "                                      os.getcwd() + \"/jars/spark-sql-kafka-0-10_2.12-3.5.1-sources.jar\", \n",
    "                                      os.getcwd() + \"/jars/kafka-clients-3.5.1-sources.jar\", \n",
    "                                      os.getcwd() + \"/jars/kafka-clients-3.5.1.jar\",  \n",
    "                                      os.getcwd() + \"/jars/spark-streaming_2.12-3.5.1.jar\",\n",
    "                                      os.getcwd() + \"/jars/commons-pool2-2.12.0.jar\",\n",
    "                                      os.getcwd() + \"/jars/spark-streaming-kafka-0-10-assembly_2.12-3.5.1.jar\",\n",
    "                                      os.getcwd() + \"/jars/spark-token-provider-kafka-0-10_2.12-3.5.1.jar\"))\n",
    "\n",
    "spark_jars_path = \"/home/rahma/Final_Project/jars/spark-sql-kafka-0-10_2.12-3.5.1.jar:/home/rahma/Final_Project/jars/spark-sql-kafka-0-10_2.12-3.5.1-sources.jar:/home/rahma/Final_Project/jars/kafka-clients-3.5.1-sources.jar:/home/rahma/Final_Project/jars/kafka-clients-3.5.1.jar:/home/rahma/Final_Project/jars/spark-streaming_2.12-3.5.1.jar:/home/rahma/Final_Project/jars/commons-pool2-2.12.0.jar:/home/rahma/Final_Project/jars/spark-streaming-kafka-0-10-assembly_2.12-3.5.1.jar\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .config(\"spark.jars\", spark_jars) \\\n",
    "                    .config(\"spark.executor.extraClassPath\", spark_jars_path) \\\n",
    "                    .config(\"spark.executor.extraLibrary\", spark_jars_path) \\\n",
    "                    .config(\"spark.driver.extraClassPath\", spark_jars_path) \\\n",
    "                    .appName(\"PySpark Streaming with Kafka\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887c3c83-6a19-42d3-9721-b42f73359490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc = StreamingContext(spark, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed84ac-2fb7-4206-8892-8043446f6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a525c42-3073-4981-9b20-13ffa68027a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6818f6d-15ec-4d51-ba68-02eb389d1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_TOPIC_NAME = \"load-balancer-logs\"\n",
    "KAFKA_BOOTSTRAP_SERVER = \"localhost:9092\"\n",
    "kafka_df = (\n",
    "        spark.readStream.format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", KAFKA_BOOTSTRAP_SERVER)\n",
    "        .option(\"subscribe\", KAFKA_TOPIC_NAME)\n",
    "        .option(\"startingOffsets\", \"earliest\") \\\n",
    "        .load()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fb32a-e9fb-4dd5-a362-a314bbe9b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kafka_df.selectExpr(\"CAST(value as STRING) as log\", \"timestamp\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6d64a5-80ed-4bc9-ba88-cb992e787a27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log_df = df.select(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb29e8-19a4-4d13-bc9f-81c6f8b5b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}) - (\\d+) \\[(.*?)\\] (\\w+) ([^\\s]+) (\\d+) (\\d+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c20dc-e71b-41e5-8c0f-cbc3ea350459",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_columns = df.withColumn(\"ip\", regexp_extract(col(\"log\"), pattern, 1)) \\\n",
    "                    .withColumn(\"uid\", regexp_extract(col(\"log\"), pattern, 2)) \\\n",
    "                    .withColumn(\"dateTime\", regexp_extract(col(\"log\"), pattern, 3)) \\\n",
    "                    .withColumn(\"method\", regexp_extract(col(\"log\"), pattern, 4)) \\\n",
    "                    .withColumn(\"filename\", regexp_extract(col(\"log\"), pattern, 5)) \\\n",
    "                    .withColumn(\"statusCode\", regexp_extract(col(\"log\"), pattern, 6)) \\\n",
    "                    .withColumn(\"fileSize\", regexp_extract(col(\"log\"), pattern, 7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37541a90-cad2-42be-aaee-2868e7da36f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab874b-8d27-407e-a600-62298501b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedCounts = df_with_columns \\\n",
    "    .withWatermark(\"timestamp\", \"5 minutes\") \\\n",
    "    .groupBy(window(col(\"timestamp\"), \"5 minutes\"))\\\n",
    "    .agg(\n",
    "    count(when((col(\"method\") == \"POST\") & (col(\"statusCode\") == \"200\"), True)).alias(\"no_of_successful_POST_operations\"),\n",
    "    count(when((col(\"method\") == \"POST\") & (col(\"statusCode\") > \"200\"), True)).alias(\"no_of_failed_POST_operations\"),\n",
    "    count(when((col(\"method\") == \"GET\") & (col(\"statusCode\") == \"200\"), True)).alias(\"no_of_successful_GET_operations\"),\n",
    "    count(when((col(\"method\") == \"GET\") & (col(\"statusCode\") > \"200\"), True)).alias(\"no_of_failed_POST_operations\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355c738-9687-48fb-9669-fd065d102a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161f9da-a9f3-44d6-90ef-5a93e58a4c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = windowedCounts.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"json\") \\\n",
    "    .option(\"path\", \"hdfs://localhost:8020/load-balancer-logs/aggregated_stream_logs\") \\\n",
    "    .option(\"checkpointLocation\", \"hdfs://localhost:8020/user/hdfs/checkpoint\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .trigger(processingTime=\"5 minute\") \\\n",
    "    .start()\n",
    "\n",
    "# query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be25a1-9957-409d-9340-978741d701d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
